# -*- coding: utf-8 -*-
"""Usohan.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1fwwXVe0678rauyFGNqJWnUa7-pOysz1U
"""

text ="""nformation can be thought of as the resolution of uncertainty; it is that which answers the question of "what an entity is" and thus defines both its essence and nature of its characteristics. The concept of information has different meanings in different contexts.[1] Thus the concept becomes related to notions of constraint, communication, control, data, form, education, knowledge, meaning, understanding, mental stimuli, pattern, perception, representation, and entropy.

Information is associated with data, as data represents values attributed to parameters, and information is data in context and with meaning attached. Information also relates to knowledge, as knowledge signifies understanding of an abstract or concrete concept.[2]

In terms of communication, information is expressed either as the content of a message or through direct or indirect observation. That which is perceived can be construed as a message in its own right, and in that sense, information is always conveyed as the content of a message.

Information can be encoded into various forms for transmission and interpretation (for example, information may be encoded into a sequence of signs, or transmitted via a signal). It can also be encrypted for safe storage and communication.

The uncertainty of an event is measured by its probability of occurrence and is inversely proportional to that. The more uncertain an event, the more information is required to resolve uncertainty of that event. The bit is a typical unit of information,"""


import spacy
from spacy.lang.en.stop_words import STOP_WORDS

from string import punctuation

stopwords =list(STOP_WORDS)

nlp =spacy.load('en_core_web_sm')

doc=nlp(text)

token =[token.text for token in doc]
print(token)

punctuation = punctuation +'\n'
punctuation

word_frequencies = {}
for word in doc:
  if word.text.lower() not in stopwords:
       if word.text.lower() not in punctuation:
            if word.text not in word_frequencies.keys():
              word_frequencies[word.text] = 1
            else:
              word_frequencies[word.text] += 1

print(word_frequencies)

max_frequency =max(word_frequencies.values())

max_frequency

for word in word_frequencies.keys():
   word_frequencies[word] = word_frequencies[word]/max_frequency

print(word_frequencies)

sentence_tokens =[sent for sent in doc.sents]
print(sentence_tokens)

sentence_scores = {}
for sent in sentence_tokens:
  for word in sent:
    if word.text.lower() in word_frequencies.keys():
      if sent not in sentence_scores.keys():
        sentence_scores[sent] = word_frequencies[word.text.lower()]
      else:
          sentence_scores[sent] += word_frequencies[word.text.lower()]

sentence_scores

from heapq import nlargest

select_length =int(len(sentence_tokens)*0.3)
select_length

summary = nlargest(select_length, sentence_scores, key = sentence_scores.get)

summary

final_summary =[word.text for word in summary]

summarys =''.join(final_summary)

print(text)

print(summarys)

from textblob import TextBlob

feedback =summarys

blob =TextBlob(feedback)

print (blob .sentiment)



# pip install gtts

from gtts import gTTS
import os

MyText=summarys

language='en'

print(MyText)

outpu =gTTS(text=MyText,lang=language,slow=False)

outpu.save("outpu.mp3")



os.system("start outpu.mp3")

from textblob import TextBlob
sohan=summarys
world10 =TextBlob(sohan)
z = world10.translate(from_lang='en' ,to ='hi')
print(z)